{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Validation & Experimentation\n",
    "\n",
    "The goal of this assignment is to practice using good experimental design and methodology to train and test classifiers.  You will write some simple code to try doing this yourself, and you will also use the tools built into scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSC 4510 - Machine Learning\n",
    "# Assignment 5\n",
    "# Scaffolding by Dr. Ben Mitchell\n",
    "# Assignment completed by: <YOUR NAME(S) HERE>\n",
    "# Resources used: \n",
    "#   <List any resources you used beyond the ones posted on Blackboard>\n",
    "#   <This can include books, websites, other students, etc.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math and numpy first\n",
    "import math\n",
    "import numpy as np\n",
    "# import scipy for stats package\n",
    "import scipy\n",
    "# import some data and classifiers to play with\n",
    "from sklearn import datasets\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import some validation tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data\n",
    "\n",
    "SciKit Learn comes with a number of \"built-in\" datasets beyond the Iris dataset we've been using (see https://scikit-learn.org/stable/datasets/index.html for a full list).  For this assignment, we will load several datasets, and compare the performance of several classifiers on each of them.\n",
    "\n",
    "First we'll load the iris dataset again, since it's small and easy to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (150, 4) target shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "# let's show the shape, just to remind ourselves\n",
    "print('dataset shape:', iris.data.shape, 'target shape:', iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Repeated hold-out validation\n",
    "We've already done 'hold-out' validation using the `train_test_split` method, but we've used a fixed seed value.  In the last assignment, we manually changed the seed for the random-number generator to get different train/test splits so we could see how the performance of our classifiers changed.  This time, let's write a loop to do the same thing for us.  Copy your code from the previous assignment to split the data 60/40 and then train and test a SVM classifier with an RBF kernel, and put it inside a `for`-loop that runs 10 times.  Each time, seed the `train_test_split` function with the current loop iteration counter (i.e. the first time through, `train_test_split` should be 0, the second time through it should be 1, etc.).  The result should be 10 accuracy scores, which should be stable (i.e. if you re-run the cell, you get the same 10 numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=i)\n",
    "  linearSvm = svm.SVC(kernel='rbf', gamma='scale')\n",
    "  linearSvm.fit(X_train, y_train)\n",
    "  linearSvm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random seed\n",
    "\n",
    "Now try making a copy of the loop, but leave off the `random_state` argument entirely.  This version of the loop should give you output that is generally similar to the previous one, but each time you re-run it, you should get different scores.  This is because the 'default' for the `train_test_split` function is to not use a static seed value, so every time you run it you'll get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4)\n",
    "  linearSvm = svm.SVC(kernel='rbf', gamma='auto')\n",
    "  linearSvm.fit(X_train, y_train)\n",
    "  linearSvm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Computing Statistics\n",
    "\n",
    "Make copy of the previous cell (i.e. the loop without fixed seeds), but this time instead of printing the individual scores, store them in a list.  The easiest way to do this is to start with an empty list (e.g. `myList = []`), and then add numbers using the `.append()` method.  After the loop is done, print out your list to be sure it looks the way you expect (you should be able to do this with a single print, e.g. `print(myList)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9333333333333333, 0.9666666666666667, 1.0, 0.9, 0.95, 0.9666666666666667, 1.0, 0.9833333333333333, 0.95, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "myList = []\n",
    "\n",
    "for i in range(10):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4)\n",
    "  linearSvm = svm.SVC(kernel='rbf', gamma='auto')\n",
    "  linearSvm.fit(X_train, y_train)\n",
    "  myList.append(linearSvm.score(X_test, y_test))\n",
    "\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average\n",
    "Compute the average of the list of numbers you made in the previous step; this is the average accuracy over your 10 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avgList(aList):\n",
    "  total = 0\n",
    "  for i in range(len(aList)):\n",
    "    total += aList[i]\n",
    "  avg = total/len(aList)\n",
    "  return avg\n",
    "\n",
    "avgList(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance & Standard Deviation\n",
    "Now compute the variance and standard deviation of your list of accuracies.  The standard deviation is the square root of the variance, and the variance is basically just the average squared differences from the mean.  \n",
    "\n",
    "This will be a bit like the loop you wrote to calculate Euclidean distance, only now you're subtracting the mean rather than a coordinate of another point, and you're going to be dividing by the number of items in the list minus one before you take the square root.  \n",
    "\n",
    "\n",
    "Note that the symbol for standard deviation is $\\sigma$; there's no standard symbol for variance, it's just $\\sigma^2$.  Here's the equations, where $N$ is the number of items in the list, $x_i$ is the $i$-th element of the list, and $\\mu$ is the mean:\n",
    "\n",
    "$ \\sigma^2 = \\frac{1}{N-1} \\sum_{i=1}^n (x_i - \\mu)^2 $\n",
    "\n",
    "$ \\sigma = \\sqrt{\\sigma^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009290123456790121"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def var(aList):\n",
    "  total = 0\n",
    "  avg = avgList(aList)\n",
    "  for i in range(len(aList)):\n",
    "    total += np.square(aList[i] - avg)\n",
    "  variance = total/(len(aList) - 1)\n",
    "  return variance\n",
    "\n",
    "var(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030479703831878223"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standDev(aList):\n",
    "  variance = var(aList)\n",
    "  stDev = np.sqrt(variance)\n",
    "  return stDev\n",
    "\n",
    "standDev(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats using scipy\n",
    "To check and see if you've calculated your statistics correctly, you can use the `scipy.stats` library.  In particular, if you call the method `scipy.stats.describe()` and give it a list of numbers as an argument, it will report a variety of statistics, including mean and variance.  Make sure that these values match the ones you've calculated above.  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.describe.html#scipy.stats.describe for documentation.\n",
    "\n",
    "In the future, it's fine to use the stats library to do this kind of thing for you, but it's a lot easier to understand the numbers coming out of the stats library once you've written code to calculate those numbers yourself.  You can also use this as a reference implementation, to check that your own code produces the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=10, minmax=(0.9, 1.0), mean=0.9616666666666666, variance=0.0009290123456790119, skewness=-0.5675817933805042, kurtosis=-0.18439090076269382)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.describe(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: K-Fold Cross-validation\n",
    "\n",
    "Now we'll use scikit-learn to do some more complicated types of validation.  Repeatedly re-spliting the data is okay, but it's not ideal from a statistical reliability standpoint (as we discussed in class).  Therefore, a better practice is to use k-fold cross-validation, as shown in this example.  Note the parameter `cv=5`; this is how many 'folds' to use, and will also be how many scores you get out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', gamma = 'auto')\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on the accuracies\n",
    "\n",
    "Since `cross_val_score` returns a numpy array, we can use some of the numpy methods to get the mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9800000000000001 , stdDev: 0.016329931618554516\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy:', scores.mean(), ', stdDev:', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated K-fold (aka N-by-K fold)\n",
    "If you try running the cross-validation cell multiple times, you'll notice you get the same values back every time.  That's because `cross_val_score` doesn't shuffle the data randomly every time you call it.  If we actually want to re-run cross-validation with a new set of point-to-fold assignmenst, we can use the function `RepeatedKFold`, to get a set of folds, and then hand it to `cros_val_score` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.96666667, 0.96666667, 1.        ,\n",
       "       1.        , 0.93333333, 1.        , 0.96666667, 0.96666667,\n",
       "       0.96666667, 1.        , 0.96666667, 0.96666667, 0.96666667])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 3)\n",
    "scores2 = cross_val_score(clf, iris.data, iris.target, cv = rkf)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy: 0.9733333333333334 , stdDev: 0.0180534186769688\n"
     ]
    }
   ],
   "source": [
    "print('mean accuracy:', scores2.mean(), ', stdDev:', scores2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try using N-by-K to compare some classifiers\n",
    "\n",
    "Last week, we tried to compare some classifiers by hand; this week, lets use cross-validation and statistics.\n",
    "\n",
    "First, we'll run 5-fold cross-validation with 4 repeats to train and test a Nearest Neighbor classifier and a Linear-kernel SVM.  Each should give you an array of 20 accuracy values.  Print the mean and standard deviation for each classifier, then print the difference between the means.  Finally, use `scipy.stats.mannwhitneyu()` to check the $p$ value and see whether the difference is statistically significant (just hand it the two score arrays as inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9549999999999998 , stdDev = 0.02640496586292476\n",
      "Linear SVM: mean = 0.9683333333333332 , stdDev = 0.02466441431158123\n",
      "Difference between means: 0.013333333333333308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=141.0, pvalue=0.04321022740214513)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 5, n_repeats = 4)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.952 , stdDev = 0.014236104336041755\n",
      "Linear SVM: mean = 0.9746666666666668 , stdDev = 0.018330302779823362\n",
      "Difference between means: 0.022666666666666835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=64.0, pvalue=9.205356621944933e-05)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 2, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.96 , stdDev = 0.04898979485566354\n",
      "Linear SVM: mean = 0.9800000000000001 , stdDev = 0.030550504633038933\n",
      "Difference between means: 0.02000000000000013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=161.0, pvalue=0.11126561552158842)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 2)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9600000000000002 , stdDev = 0.054160256030906385\n",
      "Linear SVM: mean = 0.9766666666666667 , stdDev = 0.038151743807531974\n",
      "Difference between means: 0.016666666666666496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=4252.5, pvalue=0.0159034556572305)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9587333333333334 , stdDev = 0.048343171412539965\n",
      "Linear SVM: mean = 0.9773333333333335 , stdDev = 0.037735924528226404\n",
      "Difference between means: 0.01860000000000006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=396320.0, pvalue=6.364762191037932e-21)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 100)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9615 , stdDev = 0.1636085266726646\n",
      "Linear SVM: mean = 0.979 , stdDev = 0.12672410978184065\n",
      "Difference between means: 0.01749999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=485584.0, pvalue=0.0008892385437615158)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 100, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.96005 , stdDev = 0.169053238655756\n",
      "Linear SVM: mean = 0.979 , stdDev = 0.12593252161375948\n",
      "Difference between means: 0.018950000000000022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=48548502.0, pvalue=1.9876535655988473e-23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 100, n_repeats = 100)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "scipy.stats.mannwhitneyu(nnScores, svmScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different values of K and N\n",
    "\n",
    "Repeat the above experiment using the values of K and N below, and report the mean, stdDev, differece between the means, and p-value for each.  The first row has been completed for you (note that your numbers may be slightly different, since this is a stochastic process).  Also notice how long these take to finish (though you don't need to write that down).  Once the table is complete, look at it and try to see what patterns you can spot.\n",
    "\n",
    "***\n",
    "\n",
    "Folds | Repeats  |   NN-mean  |  NN-stdev  | SVM-mean  |  SVM-stdDev  |  difference   |  p-value\n",
    "------|----------|------------|------------|-----------|--------------|---------------|--------------\n",
    "5     |      4   |    0.957   |   0.035    |  0.977    |   0.032      |     0.033     |   0.032\n",
    "2     |      10  |    0.952   |   0.014    |  0.974    |   0.018      |     0.022     |   9.205e-05\n",
    "10    |      2   |    0.960   |   0.048    |  0.98     |   0.031      |     0.020     |   0.111\n",
    "10    |      10  |    0.960   |   0.054    |  0.977    |   0.038      |     0.017     |   0.016\n",
    "10    |     100  |    0.959   |   0.048    |  0.977    |   0.038      |     0.018     |   6.365e-21\n",
    "100   |      10  |    0.962   |   0.164    |  0.979    |   0.127      |     0.017     |   0.001\n",
    "100   |     100  |    0.960   |   0.169    |  0.979    |   0.126      |     0.019     |   1.988e-23\n",
    "\n",
    "\n",
    "* All answers were rounded to the nearest thousandth place\n",
    "* The p-value was reported to nearest thousandth plus their scientific notation component if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Alternative Metrics\n",
    "\n",
    "Up until now, we've just worked with overall accuracy as our only way of \"scoring\" the performance of a classifier.  Now, we will try out some alternative tools for evaluating classifier performance.  In addition to the `.scores()` method, scikit-learn classifiers have a `.predict()` method which takes in a set of examples as an argument, and returns an array with the predicted labels for those examples.  Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted labels:  [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 1 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2]\n",
      "true labels:  [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "print('predicted labels: ', predictions)\n",
    "print('true labels: ', testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "By comparing the predicted labels to the 'true' labels, we could easily compute accuracy like we've done in the past.  This time, however, we want to drill down and get more details, so we're going to build a confusion matrix.\n",
    "\n",
    "A confusion matrix works by making a 2D array (i.e. a matrix), with the rows corresponding to 'true' class labels and the columns corresponding to 'predicted' class labels.  You just need to loop over the pairs of corresponding true/predicted labels, and add to the count in the corresponding cell of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.,  0.,  0.],\n",
       "       [ 0., 22.,  1.],\n",
       "       [ 0.,  1., 20.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confMatrix(predict, truth):\n",
    "  truthValues = len(np.unique(truth)) # Number of classes \n",
    "  confusion = np.zeros((truthValues, truthValues))\n",
    "\n",
    "  for i in range(len(truth)):\n",
    "    confusion[truth[i]][predict[i]] += 1\n",
    "\n",
    "  return confusion\n",
    "\n",
    "confMatrix(predictions, testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix using scikit-learn\n",
    "\n",
    "We can also ask scikit-learn to generate a confusion matrix for us, as the following example shows.  Your own confusion matrix should look just like the one produced by the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  1 20]]\n"
     ]
    }
   ],
   "source": [
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancy Graphics\n",
    "\n",
    "It's also possible to use Python's plotting tools to make fancy graphical versions of a confusion matrix; the following example is adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html.  _NOTE:_ it's fine if you don't understand what this function is doing; we haven't really covered making plots yet.  For now, it's okay if this is just magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3xUVfrH8c+XRIrSBUsSXBBUJOqKFHtZxUrTFRULith735+rrmJva9dd110VO4hlqYquLq6dpqgUNUoQElREBGuQ+Pz+ODc4GZLMSCaZmeR585oXc+eeOffcyeTJOeeee47MDOecc7XTJN0FcM65hsCDqXPOpYAHU+ecSwEPps45lwIeTJ1zLgU8mDrnXAp4MHWVSBop6dHo+WaSvpOUk+JjFEvql8o8kzjmaZK+iM5nw1rk852kzVNZtnSRNEfSXukuR0PhwbSeRYHkC0kbxLx2oqSpaSxWlczsMzNraWbl6S5LbUhaD7gV2C86n2Xrmlf0/k9TV7rUkzRK0jWJ0plZoZlNrYciNQoeTNMjFzintpko8J9hYhsDzYE56S5IJpCUm+4yNET+i5geNwMXSmpb1U5Ju0iaLmlF9P8uMfumSrpW0uvAD8Dm0WvXSHojaoZOkLShpMckrYzy6ByTxx2SFkX7ZkravZpydJZkknIl7RzlXfH4SVJxlK6JpIslfSJpmaQnJbWPyWeYpIXRvktr+mAktZB0S5R+haTXJLWI9g2KmqbfROe8dcz7iiVdKOm96H1jJDWXtCXwYZTsG0kvx55X3Od6YvS8m6RXony+kjQmJp1J6hY9byPpYUlLo/JeVvHHTdLwqOx/lbRc0gJJB9Zw3sWSLorK/72k+yVtLOk5Sd9K+o+kdjHpx0r6PCrj/yQVRq+fDBwN/KniuxCT//9Jeg/4PvqZrulukTRZ0i0x+Y+R9EBNPysXx8z8UY8PoBjoBzwDXBO9diIwNXreHlgODCPUYI+MtjeM9k8FPgMKo/3rRa8VAV2BNsBc4KPoOLnAw8CDMWU4Btgw2ncB8DnQPNo3Eng0et4ZMCA37hwqjnl9tH0u8BZQADQD/gE8Ee3rAXwH7BHtuxVYDfSr5vO5J8o7H8gBdonetyXwPbBvdPw/RefcNOZznQbkRZ/hPODUqs6jqvOKjnli9PwJ4FJCZaM5sFtMOgO6Rc8fBsYBraI8PwJOiPYNB34GTorO4zSgFFAN34u3CLXofOBLYBbQMzr/l4ErYtKPiI7bDLgdeDdm3yii71Zc/u8CnYAWsd/F6Pkm0TH3JgTjT4FW6f59yaZH2gvQ2B78Gky3AVYAHakcTIcB0+Le8yYwPHo+Fbgqbv9U4NKY7VuA52K2B8b+slVRpuXA76PnI0kcTP8OTAKaRNvzgH1i9m8aBZJc4HJgdMy+DYBVVBFMo+D1Y0VZ4vb9BXgyLm0JsFfM53pMzP6bgHurOo+qzovKwfRh4D6goIpyGNCNECDLgB4x+06J+TkOB4pi9q0fvXeTGr4XR8dsPw38PWb7LODf1by3bZR3m2h7FFUH0xFVfRdjtv8ILAK+IuYPiD+Se3gzP03M7ANgInBx3K48YGHcawsJtZUKi6rI8ouY5z9Wsd2yYkPSBZLmRU3Ebwi12Q7JlFvSKcBewFFm9kv08u+AZ6Pm9zeE4FpOqGXlxZbXzL4HqrsA1IFQE/ykin2VPpfo2Iuo/Ll8HvP8B2LO+Tf6EyBgWtStMKKasjal8s8q/ue0pjxm9kP0tKYyJfUzlJQj6YaoW2UlIShWlKkmVX1vYk0k/JH40MxeS5DWxfFgml5XEJqBsb+ApYTgFGszQi2swjpP9RX1j/4fcDjQzszaEmrISvK9VwODzWxFzK5FwIFm1jbm0dzMSoAlhKZlRR7rE7oYqvIV8BOhuyJepc9FkqJ8S6pIm8j30f/rx7y2ScUTM/vczE4yszxCbfNvFf2kcWX9mco/q/ifU105ChhMaOG0IdS04defYXXfj0Tfm2sJfwg3lXRkLcvY6HgwTSMzKwLGAGfHvDwZ2FLSUdFFgiMI/Y4TU3TYVoQ+y6VArqTLgdaJ3iSpU1TWY83so7jd9wLXSvpdlLajpMHRvqeAAZJ2k9QUuIpqvndRbfMB4FZJeVENbGdJzYAngf6S9lEY6nQBoZn9xm86+3CcpYSgd0x0jBHEBHBJh0kqiDaXE4JQeVwe5VGZrpXUKjr384FHf2t51kErwrkvI/xBuC5u/xfAbxoLK2kP4Hjg2Ohxl6T8mt/lYnkwTb+rCP2IAFgYAzmAECyWEZqcA8zsqxQdbwrwHOFiyUJCTTBR8w9gH0Lt7Sn9ekW/YqjRHcB44AVJ3xIupOwYnc8c4AzgcUItdTmwuIbjXAi8D0wHvgZuJPTNfki4cHYXoVY4EBhoZquSPO94JwEXET7jQioH5T7A25K+i87rHDNbUEUeZxFquZ8Cr0XnWB9XwB8m/OxKCBcb34rbfz/QI+p2+XeizCS1jvI808xKoib+/cCDUQvAJUFRx7Nzzrla8Jqpc86lgAdT51yjIukBSV9K+qCa/ZJ0p6Si6CaKHZLJ14Opc66xGQUcUMP+A4EtosfJhHHVCXkwdc41Kmb2P8LFzeoMBh624C2graRNE+XrEx6sA+W2MDVtle5iZISeW2+W7iK4DDVr1syvzKxjqvLLaf07s9U/JkxnPy6dQxilUuE+M7vvNxwqn8ojXBZHry2p6U0eTNeBmrai2VaHp7sYGeH1t+9OdxFchmqxnuLv5KsVW/1jUr93P717z09m1rsWh6pqOFjCYU8eTJ1z2UGCJimdp7w6i4m5a48wgU9pojd5n6lzLnuoSeJH7Y0Hjo2u6u8ErDCzGpv44DVT51w2ScENWZKeIEzW00HSYsIcGesBmNm9hFu6DyJM8fgD4TbbhDyYOueyhFJS8zSzGidxsXBb6Bm/NV8Pps657CDqq890nXgwdc5lCaWkmV9XPJg657JHBq8f6cHUOZc9vGbqnHO1VH/jTNeJB1PnXPbwZr5zztVWaoZG1RUPps657NHE+0ydc652fJypc86lgjfznXMuNXxolHPO1ZIPjXLOuRTxZr5zzqWAN/Odc662/AKUc87Vng+Ncs65VPCaqXPOpYb3mTrnXAp4zdQ552rJx5k651yKZHAzP3PrzI3YvVcczcKXrmfG2EuqTXPLn4bwwbgrmDbmz2zfvWDN60cP3JH3x13O++Mu5+iBO9ZHcevcC1OeZ7vCrSjs3o2bb7phrf1lZWUcc9QRFHbvxu677MjC4uI1+26+8XoKu3dju8KtePGFKfVY6rrR2D8LSQkf6eLBNAM9MuEtBp9xT7X799+tB10368g2g6/kzGue4M5LhgLQrvX6XHrygewx7K/sfszNXHrygbRt1aK+il0nysvLOffsMxg34TneeW8uY0c/wby5cyulGfXA/bRr244584s465zzuPSS/wNg3ty5jB0zmlmz5zB+4vOcc9bplJeXp+M0UqKxfxYSqIkSPtLFg2kGen3WJ3y94odq9w/YczsenzgNgGnvF9OmVQs26dCafXfZmpfems/ylT/wzbc/8tJb89lv1x71Vew6MX3aNLp27UaXzTenadOmHHbEUCZOGFcpzcQJ4zh62HEA/PHQIUx9+SXMjIkTxnHYEUNp1qwZnbt0oWvXbkyfNi0dp5ES/lkkrpV6zdT9JnkbtWXx58vXbJd88Q15G7Ulr2NbFn8R8/qX35DXsW06ipgypaUlFBR0WrOdn19ASUnJ2mk6hTS5ubm0btOGZcuWUVKy9ntLSyu/N5v4Z+HN/DonabikvHSXo75U9X0xs6pfx+q+QHXIbO3yx//CVJsmifdmE/8sPJjWh+FAowmmJV98Q8Em7dZs52/cliVLV1Dy5TcUbBzz+kbh9WyWn1/A4sWL1myXlCwmLy9v7TSLQprVq1ezcsUK2rdvT37B2u/ddNPs/Zo0+s/C+0zXjaQNJE2SNFvSB5KOkNRL0iuSZkqaImlTSUOA3sBjkt6V1ELSPpLekfS+pAckNYvyvEHSXEnvSfpr9NpASW9H6f8jaeN0nncyJr3yPkcN6AtA3207s/K7H/n8q5W8+MY8+u3cnbatWtC2VQv67dydF9+Yl+bS1k7vPn0oKvqY4gULWLVqFWPHjKb/gEGV0vQfMIjHHnkIgGeefoo9/7A3kug/YBBjx4ymrKyM4gULKCr6mD59+6bjNFKisX8WyvA+00weZ3oAUGpm/QEktQGeAwab2VJJRwDXmtkISWcCF5rZDEnNgVHAPmb2kaSHgdOi/w8BupuZSaroTHwN2Cl67UTgT8AF8YWRdDJwMgDrtazD04aHrh/O7r22oEPblhQ9fzVX3zuZ9XLDYOV/PfUaz782h/13K2TO+Cv44aefOWXkowAsX/kD1//zeV579E8AXHff8yxfWf2FrGyQm5vLbXfczcD++1NeXs5xw0fQo7CQq0Zezg69ejNg4CCGjziBEcOHUdi9G+3ateeRx0YD0KOwkEMPO5ye2/UgNzeX2++8h5yczB30nYh/FpndNaGq+lgygaQtgSnAk8BEYDnwBvBplCQHWGJm+0mayq/B9PfAXWa2R5TPPsAZwOHATGAGMAmYaGarJG0L3AJsCjQFFpjZATWVrcn6G1mzrQ5P6flmq+XT7053EVyGarGeZppZ71Tll7vh5tb6oGsSplv+6NEpPW6yMraZb2YfAb2A94HrgUOBOWa2ffTY1sz2q+KtVf7pMrPVQF/gaeBg4Plo113A3Wa2LXAK0Dy1Z+KcS4kM7zPN2GZ+dHX+azN7VNJ3hCZ2R0k7m9mbktYDtjSzOcC3QKvorfOBzpK6mVkRMAx4RVJLYH0zmyzpLaAoSt8GqBgjclw9nZ5zbh1kcjM/Y4MpsC1ws6RfgJ+B04DVwJ1R/2kucDswh9BHeq+kH4GdgeOBsZJygenAvUB7YFzUpyrgvOg4I6O0JcBbQJd6OTvn3G9ScQEqJXlJBwB3ELoL/2VmN8Tt3wx4CGgbpbnYzCbXlGfGBlMzm0LoM423RxVpnyY03yu8BPSMS7aE0MyPf+84YFz86865zJOKYCopB7gH2BdYDEyXNN7MYu/NvQx40sz+LqkHMBnoXFO+Gdtn6pxzlaSuz7QvUGRmn5rZKmA0MDgujQGto+dtgNJEmWZszdQ55+IlWTPtIGlGzPZ9ZnZfzHY+sChmezEQP8XaSOAFSWcBGwD9Eh3Ug6lzLmskGUy/SjA0qqpM4seIHgmMMrNbJO0MPCJpGzP7pbpMPZg657KCSNnQp8VAp5jtAtZuxp9AuHGIaPRQc6AD8GV1mXqfqXMuOyhlE51MB7aQ1EVSU2AoMD4uzWfAPgCStiaMP19aU6ZeM3XOZY1UXM03s9XRLehTCMOeHjCzOZKuAmaY2XjCLeX/lHQeoQtguCW4XdSDqXMua6RqnGk0ZnRy3GuXxzyfC+z6W/L0YOqcyxrpvF00EQ+mzrmskO4p9hLxYOqcyxoeTJ1zLgU8mDrnXAp4n6lzztWWvGbqnHO1JqpemTdTeDB1zmUJv5rvnHMp0cT7TJ1zrpbkzXznnKs14TVT55xLCQ+mzjlXW97Md8652gtDozI3mnowdc5lCR8a5ZxzKeF9ps45V1veZ+qcc7XnfabOOZciGRxLPZg657KH95k2MD233ozX37473cXICO32uizdRcgYpS9cme4iNGw+BZ9zztWeT8HnnHMpIW/mO+dcKngz3znnasvHmTrnXO35OFPnnEsR7zN1zrkU8Jqpc87VlveZOudc7cmn4HPOudTIyeA+0ybV7ZDUuqZHfRbSOecgNPMTPZLLRwdI+lBSkaSLq0lzuKS5kuZIejxRnjXVTOcARhiRUKFi24DNkiu2c87VnlJ0b76kHOAeYF9gMTBd0ngzmxuTZgvgz8CuZrZc0kaJ8q02mJpZp1qX2jnnUihFrfy+QJGZfQogaTQwGJgbk+Yk4B4zWw5gZl8mLFsyR5Y0VNIl0fMCSb1+Y+Gdc67WmjRRwgfQQdKMmMfJcdnkA4tithdHr8XaEthS0uuS3pJ0QKKyJbwAJeluYD1gD+A64AfgXqBPovc651yqiHBFPwlfmVnvBFnFs7jtXGALYC+gAHhV0jZm9k11mSZTM93FzE4BfgIws6+Bpkm8zznnUqqJEj+SsBiI7cYsAEqrSDPOzH42swXAh4TgWn3Zkjjwz5KaEEVuSRsCvyRVZOecSxUlbuInebvpdGALSV0kNQWGAuPj0vwb+EM4rDoQmv2f1pRpMsH0HuBpoKOkK4HXgBuTKbFzzqWKgCZSwkciZrYaOBOYAswDnjSzOZKukjQoSjYFWCZpLvBf4CIzW1ZTvgn7TM3sYUkzgX7RS4eZ2QcJS+yccymWqhugzGwyMDnutctjnhtwfvRISrJ3QOUAPxOa+kmNAHDOuVTL5NtJEwZGSZcCTwB5hI7axyX9ua4L5pxzsaRwO2miR7okUzM9BuhlZj8ASLoWmAlcX5cFc865eJlbL00umC6MS5dLgqtazjlXFzK5mV9tMJV0G6GP9AdgjqQp0fZ+hCv6zjlXb8LV/HSXono11UwrrtjPASbFvP5W3RXHOeeqoSxd6tnM7q/PgjjnXCKZ3MxP5mp+V0mjJb0n6aOKR30UrrF6YcrzbFe4FYXdu3HzTTestb+srIxjjjqCwu7d2H2XHVlYXLxm3803Xk9h925sV7gVL74wpR5LXTf23XELZj9+Dh+MPo8Lj9ljrf2bbdyWybcfz7RRZzLlrhPI7/jrVLudNm7DhFuH886jZzPrkbPZbJO29Vn0OvGfF56n7/Y96LXtVtz+17XvnSkrK2PEsUfSa9ut6Lfnzny2sLjS/sWLPqPTRm246/Zb6qnEqVPRzE/B7aR1Ipkxo6OABwnnciDwJDC6DsvUqJWXl3Pu2WcwbsJzvPPeXMaOfoJ5c+dWSjPqgftp17Ydc+YXcdY553HpJf8HwLy5cxk7ZjSzZs9h/MTnOees0ykvL0/HaaREkybi9vMHMvjCh+l5zJ0c1m9bunfuWCnN9WcewGPPv0vf4Xdz3YP/5apT9luz71+XDeG2x1+l5zF3svvJ97J0+ff1fQopVV5ezp/OP5snn53ImzPf5+mxY5g/r/J349GHHqBt23bMfP9DTjvzXEb+pfIoxkv+7wL22S/hBEgZS1LCR7okE0zXN7MpAGb2iZldRnTPqku96dOm0bVrN7psvjlNmzblsCOGMnHCuEppJk4Yx9HDjgPgj4cOYerLL2FmTJwwjsOOGEqzZs3o3KULXbt2Y/q0aek4jZTos3UBnyxeRnHpcn5eXc7Y/7zPgN22rpSme+eOTJ35CQCvzPqUAbt3X/N6bk4TXp4R9n3/4yp+LPu5fk8gxWbOmEaXzbvSuUv4bvxxyOE8N7HyLeWTJ45n6NHDABh8yKH8b+rLhJt5YNKEcXTu3IXuW/eo97KnggQ5UsJHuiQTTMsUwv0nkk6VNBBIOOu0WzelpSUUFPw6oU1+fgElJSVrp+kU0uTm5tK6TRuWLVtGScna7y0trfzebJLXsTWLv1yxZrtk6cpKzXiA94s+5+C9CgEYvEcPWm/QnPatW7BFpw588+2PjL72SN584HSuO33/jL54kYwlpaXkx/x88/ILWLKktNo0ubm5tG7dhq+XLeP777/njltv4k+XXE42S9WyJXUhmWB6HtASOBvYlTAD9Yi6LFRVokkI+iVOudb79pI0sS7KVBcqahGx4psu1aZJ4r3ZpKqix5/7n+9+nt2378ybD5zO7j07U/LlClaX/0JuThN2/X1nLr7neXY76V665LVn2IE71FPJ60ZS3421puUMaW64ZiSnnXkuLVu2rKvi1YtMbuYnM9HJ29HTb4FhdVmYqAYsM1trir/YSQjquAy50awyaZGfX8Dixb9OAl5Sspi8vLy10yxaREFBAatXr2blihW0b9+e/IK137vpppXfm01KvlxJwUZt1mznd2xN6VffVkqzZNm3DL30CQA2aNGUg/csZOX3ZZQsXcHsj5dQXLocgPGvzqNvYQEPTSJr5eXnUxLz8y0tWcwmm2xaOU1eSJOfH303Vq6gXfv2zJwxjfH/foaRl13MihXf0KRJE5o3b85Jp55R36exzkR6bxdNpKbVSZ+V9Ex1j5oylXSjpNNjtkdKukDSRZKmRyMDroz2dZY0T9LfgFlAJ0mjJH0g6X1J50XpRkkaEj3vI+kNSbMlTZPUSlJzSQ9G73lH0lr9upLaS/p3dPy3JG0XU777JL0APLwOn2PK9O7Th6KijylesIBVq1Yxdsxo+g8YVClN/wGDeOyRhwB45umn2PMPeyOJ/gMGMXbMaMrKyihesICioo/p07dvOk4jJWbML6Fbpw353abtWC83h8P6bcuk1+dXSrNhm/XX1EYuGrYHD02aFd47r4S2rZrToe36AOy1w+bML15avyeQYjv06sOnnxSxsDh8N5556kkO6D+wUpoD+w9k9GOPADDu2afZfc8/IInJL77C7HmfMHveJ5x6xtmcd+HFWRVIAUiiiZ/OhlhNNdO7a5HvaOB24G/R9uHADcBuhMWsBIyXtAfwGbAVcLyZnR6tL5VvZtsASKo0niWazHUMcISZTVdYdvpH4BwAM9tWUnfgBUlbxpXrSuAdMztY0t6EwLl9tK8XsJuZ/VjVCUXryJwM0GmzuluYNTc3l9vuuJuB/fenvLyc44aPoEdhIVeNvJwdevVmwMBBDB9xAiOGD6OwezfatWvPI4+FwRU9Cgs59LDD6bldD3Jzc7n9znvIycmps7LWtfLyXzjv1olMuPU4cpo04aFJM5m34Ev+csI+zJpfwqTX57NHzy5cdcq+GPDau8Wce+sEAH75xfjz3c8z+fYRSPDOh6U8MH5Gek+olnJzc7npljsYMvggysvLOfrY4Wzdo5Drrr6Cnjv05sD+AznmuBGceuJx9Np2K9q1a8e/Hkq4QnFWyeRuK1XVD5OSjKV5wD5AR0JQfRMYAlSsodKSMFnKS8B/zaxL9L52wAzCXIOTgBfM7BdJo4CJhOUD7jWzXeOO9yxwl5m9HG2/CpwBtAcuNLMBkt4BDo1ZlXARsA2hX9jM7Mpkzq1Xr972+tvZ/YuZKu32uizdRcgYpS8k9fVpNNpvkDszwVpMv8lG3baxI24emzDd3X/skdLjJivZ+UzXxVOE4LkJoabaGbjezP4Rm0hSZ2DNAMBojerfA/sTguHhVL7gJdZe/Kri9URqWkgruwchOtfACbKzzzQFRhPWVhlCCKxTgBGSWgJIype01hCraL2VJmb2NPAXIP4S7HwgT1KfKH0rSbnA/4Cjo9e2BDYj1GJjxabZi7CK4cran6pzrj5k8h1QSddMJTUzs7Jk00drqrQCSsxsCbBE0tbAm1G/x3eEuVLjb9HJBx5UWMQPoNItHGa2StIRwF2SWhD6S/sRuhLulfQ+sBoYbmZlcX0sI6O83yPMhnVcsufjnEuvcIEpc2umCYOppL7A/UAbYLOoCX6imZ2V6L1mtm3c9h3AHVUk3SYmzWzWro1iZsNjnk8Hdqoin+HxL5jZVGBq9PxrYHAVaUZWVX7nXGbJ4FZ+Us38O4EBwDJYE+z8dlLnXL2q6DPN5mVLmpjZwrjqdfbOnuGcy1qZvJpnMsF0UdTUN0k5wFmAT8HnnKt3GdxlmlQwPY3Q1N8M+AL4T/Sac87VG0k0yeBomsy9+V8Shjg551xa5WRwOz+Zq/n/pIpB8mZ2cp2UyDnnqhBm2s/imimhWV+hOXAIsKiatM45V2cyOJYm1cwfE7st6RHgxTorkXPOVSWaaT9Trcu9+V2A36W6IM45V5OKBfUyVTJ9psv5tc+0CfA1cHFdFso556qStcE0mvn+90DFQkK/WF3N2eeccwlk8r35NQ40iALns2ZWHj08kDrn0kIKQ6MSPZLLSwdI+lBSkaRqW9qShkgySQnnR03m0NMkZfdKZM65BqFJNHC/pkci0Z2c9wAHAj2AIyWttf51NOvd2cDb8fuqLFsNB6zoAtiNEFA/lDQrWl9pVjKZO+dcqlRcgErBfKZ9gSIz+9TMVhHmXl5rNjngauAm4KdkMq2pz3QaYSq8g5MqnnPO1bEUdZnmU3ms/GJgx8rHUU+gk5lNlHRhMpnWFEwFYGaf/MaCOudcygklO860g6TYRdruM7P7KmW1tjXXg6KJ6W+jivmRa1JTMO0o6fzqdprZrb/lQM45VyvJN+O/SrCg3mKgU8x2AVAas92KMGH91Gj0wCaE1ZQHmVm1K2nWFExzCCuIZu5YBOdco5Kie/OnA1tI6kIY9jkUOKpip5mtADpUbEuaSljhuMYliWsKpkvM7KralNg551IlVauTmtlqSWcSFvnMAR6I1qy7CphhZuPXJd+EfabOOZcpUjVm38wmA5PjXru8mrR7JZNnTcF0n6RL5pxzdUxk6bIl0UqezjmXGbJ9qWfnnMsEouFNweecc2mRuaHUg6lzLotkcMXUg6lzLlvI+0ydc662vM/UOedSJHNDqQdTV0slU0amuwgZI2//K9NdhIbNh0Y551ztZe2gfeecyzQpmuikTngwdc5ljQyOpR5MnXPZITTzMzeaejB1zmWJ5BbMSxcPps65rJHBsdSDqXMuO3gz3znnUkFeM3XOuZTwPlPnnKslkfTqpGnhwdQ5lzXkfabOOVd7GdzK92DqnMsOPgWfc86lhLyZ75xzteZDo5xzLjUyOJZ6MHXOZQfvM3XOuVTJ3FjqwdQ5lz38ApRzzqWA3wHlnHOp4MHUOedqR3gz3znnai/Dx5lm8sqpzjlXiZT4kVw+OkDSh5KKJF1cxf7zJc2V9J6klyT9LlGeHkydc1lCSf1LmIuUA9wDHAj0AI6U1CMu2TtAbzPbDngKuClRvh5MM9ALU55nu8KtKOzejZtvumGt/WVlZRxz1BEUdu/G7rvsyMLi4jX7br7xegq7d2O7wq148YUp9VjquvHSi1Po27OQ3tt15/Zb1v4+l5WVccKxR9F7u+7su9cufLawGIDPFhaT36EVe+7ciz137sUFZ59ezyWvG/v27cbsx87mgyfO4cKjd19r/2Ybt2Hy7cOZNup0ptx5PPkdW6/Z993Ukbz1wGm89ZIpd2YAABeXSURBVMBpjL3+qPosdsqkqGbaFygys0/NbBUwGhgcm8DM/mtmP0SbbwEFiTL1PtMMU15ezrlnn8Gk514kv6CA3Xbqw4ABg9i6x69/OEc9cD/t2rZjzvwinhwzmksv+T8efXwM8+bOZeyY0cyaPYclpaUcdEA/3p/7ETk5OWk8o3VXXl7On84/m6fHP0defgH99tiJAw4aQPetf/0sHn3oAdq2bcuM9+bzzNgxXPmXS7j/4ccB6NylK6+8OTNdxU+5Jk3E7ecPoP95D1GydCWv/fMUJr4+n/nFS9ekuf6M/Xns+Xd57Pl32XOHLlx1Sj9OuOYZAH4s+5mdRvw9XcWvNZH0xfwOkmbEbN9nZvfFbOcDi2K2FwM71pDfCcBziQ7qNdMMM33aNLp27UaXzTenadOmHHbEUCZOGFcpzcQJ4zh62HEA/PHQIUx9+SXMjIkTxnHYEUNp1qwZnbt0oWvXbkyfNi0dp5ESs2ZMo8vmXencJXwWhww5gucmTaiU5rlJExh69DAABh1yKP+b+jJmlo7i1rk+WxfwScnXFC9Zzs+ryxn70vsM2K17pTTdO2/E1JmfAvDKrAVr7c92khI+gK/MrHfM4774bKrIusovjaRjgN7AzYnK5sE0w5SWllBQ0GnNdn5+ASUlJWun6RTS5Obm0rpNG5YtW0ZJydrvLS2t/N5ssqS0lPyCX1tXefn5LIk7nyWlpeQVVP4svl62DIDPFi5gr116M3D/vXnz9dfqr+B1JK9jKxZ/uWLNdsnSleR3aF0pzftFn3PwnqHmPniPrWm9QXPat24BQPOmubz2z1N45d6TGLh7dgbZFDXzFwOdYrYLgNK1j6V+wKXAIDMrS5Rp2pv5kvKAO81syG9837+AW81sbg1pTgV+MLOHa1nMelNVrUpx35Bq0yTx3mxSm89i4002Zfa8T2m/4Ya8+85Mhg0dwuvTZ9O6deu10meLqi6uWFyF6s/3TOG28/pzzIE9eX12MSVfrmB1+S8AbDnkVpYs+5bOm7bj+TuG88EnX7CgdHm9lD1VUvRtng5sIakLUAIMBSp1IkvqCfwDOMDMvkwm07QHUzMrBdYKpJJyzWx1De87MYm8761l8epdfn4Bixf/2p1TUrKYvLy8tdMsWkRBQQGrV69m5YoVtG/fnvyCtd+76aaV35tN8vLzKVm8eM12aUkJm8SdT15+PqWLF5Gf/+tn0a59eyTRrFkzALbv2YsuXTbnk6KP6LlD73o9h1QqWbqSgo3arNnO79ia0q++rZRmybJvGXrZaAA2aNGUg/fswcrvy9bsAyhespz/vVvM9ltuml3BVKmpHJjZaklnAlOAHOABM5sj6SpghpmNJzTrWwJjo2N+ZmaDasq3Xpv5km6UdHrM9khJF0j6INoeLmmspAnAC5KaSPqbpDmSJkqaLGlIlHaqpN7R8+8kXStptqS3JG0ck/+F0fNukv4TpZklqaukltEYslmS3pc0eK1C17PeffpQVPQxxQsWsGrVKsaOGU3/AZV/hv0HDOKxRx4C4Jmnn2LPP+yNJPoPGMTYMaMpKyujeMECioo+pk/fvuk4jZTo2asPn35SxMLi8Fk8+9QYDjxoQKU0Bxw0gNGPPQLA+GefZvc9/4Akvlq6lPLycgCKF3zKJ58U0bnz5vV+Dqk0Y34J3Qra87tN27Jebg6H7bMtk16bXynNhm3WXxNwLjpmdx6a/A4AbVs2p+l6OWvS7LzNZsyLuXCVDUTqxpma2WQz29LMuprZtdFrl0eBFDPrZ2Ybm9n20aPGQAr1XzMdDdwO/C3aPhw4FTg+Js3OwHZm9nUUODsD2wIbAfOAB6rIdwPgLTO7VNJNwEnANXFpHgNuMLNnJTUn/CFZBRxiZisldQDekjTe0ngFIzc3l9vuuJuB/fenvLyc44aPoEdhIVeNvJwdevVmwMBBDB9xAiOGD6OwezfatWvPI4+FmkiPwkIOPexwem7Xg9zcXG6/856svZIP4bO48ZY7OOzg/pSXl3PUsOF071HI9VePZPsdenFg/4Ecc9wITjtxOL23607bdu3416jHAHjj9Ve54Zoryc3NIScnh1vuuId27dun+Yxqp7z8F867bRITbjmWnCZNeGjSLOYVL+UvJ+zNrPklTHr9Q/bo2ZmrTt4Xw3ht9kLOvXUiAN07d+SuCwfxixlNJP762KuVRgFki0zutFJ9xw1J84B9gI6EoHo0MNHMtpE0HNjTzI6P0t4OzDazB6PtZ4DHzewpSVOBC81shqQyoLmZmaQjgH3N7ERJI4HvCH0f88ysIK4s6wG3AXsAvwBbAV3M7PMqyn0ycDJAp8026/XRJwtT+rlkqx/Kqu2JaXTyD7gq3UXIKD+9dvVMM0tZv8o2v9/Bxj7/asJ0PfJapvS4yUpHn+lThD7STQg11XjfxzxP9g/RzzG1yXLWPq/q8jmaENR7mdnPkoqB5lUljIZX3AfQq1fvhjn2xrkM1ySDL6imY2jUaMLVsyGEwFqT14BDo77TjYG91uWAZrYSWCzpYABJzSStD7QBvowC6R+AhPffOufSR0k80qXeg6mZzQFaASVmtiRB8qcJY8I+IDTV3wZW1PiO6g0Dzpb0HvAGoWb8GNA7ulviaGB+De93zqVbBkfTtAyNMrNtY54XA9tEz0cBo2L2/SLpQjP7TtKGwDTg/WjfXjHpWsY8f4qoxmtmI2Ne/xjYu4ri7Fz7M3LO1TWfz7T2JkpqCzQFrq7q4pBzrhGQL1tSK7E1UOdcI+fB1Dnnaiu5+UrTxYOpcy5rZPDIKA+mzrnsUHE7aabyYOqcyxrezHfOuRTwmqlzztWWD41yzrlUydxo6sHUOZcV/AKUc86lSAbHUg+mzrnskclT8Hkwdc5lj8yNpR5MnXPZI4NjqQdT51x2+C0L5qWDB1PnXNZIxVLPdcWDqXMua2RuKPVg6pzLIhlcMfVg6pzLFj6fqXPO1ZrfAeWccyniwdQ551LAm/nOOVdL8in4nHMuRTyYOudc7WVyM79JugvgnHPJqriltKZHcvnoAEkfSiqSdHEV+5tJGhPtf1tS50R5ejB1zmWNVARTSTnAPcCBQA/gSEk94pKdACw3s27AbcCNifL1YOqcyxpK4l8S+gJFZvapma0CRgOD49IMBh6Knj8F7KMEEwN4n+k6mDVr5lct1tPCdJcD6AB8le5CZAj/LH6VKZ/F71KZ2TuzZk5Zv6k6JJG0uaQZMdv3mdl9Mdv5wKKY7cXAjnF5rEljZqslrQA2pIbP1YPpOjCzjukuA4CkGWbWO93lyAT+WfyqoX4WZnZAirKqqoZp65CmEm/mO+cam8VAp5jtAqC0ujSScoE2wNc1ZerB1DnX2EwHtpDURVJTYCgwPi7NeOC46PkQ4GUzq7Fm6s387HZf4iSNhn8Wv/LPogZRH+iZwBQgB3jAzOZIugqYYWbjgfuBRyQVEWqkQxPlqwTB1jnnXBK8me+ccyngwdQ551LAg6lzzqWAB1PX6CS6k8W5deHB1DUqklQxxEXSMEm7pbtMrmHwYNpARQONXZyYQHoAYbjLh+ktUXp47Tz1/BeuAZJ0OrCjpGLgP2b2apqLlFEk9QVGALPNbGn0mhINym4oKs5V0r7AlkCZmf0r3eXKdl4zbWAknQEcBtxNmB3nOkkD01uq9KqiFrYM+AzYTtKuEGqsjaW2Fp3rQcDtwEfALZJuiKamc+vIg2kDIqk10A4YBOwSvfwQcJGk/mkrWBrF9ZEOiD6HjsAVwLvAQEk7w69dAA2dpPbAOcARhBjwMXAAcK8kjwnryD+4BkLS9ma2ErgLyCME1D8S7jHOAc6QtEFjqX3FEICkU4HrgN7AM8AhwB1AGXBU1PRvsCp+7pLam9nXwFGEWZCuiWaYOogwIfJVjfA7khIeTBsASecQfgkKzGwF4ef6I+GXZS9gBjDczL5vRLWv7lGt9BdJeYSLTUeZ2ZWEWtjVwK7A34ElwIL0lbZuxfSRDgCekLSpmS0jXDP5TFIzQm39UWBKY/mOpJpfgMpykgYTahn7m9k3kjYxs3mSSoAnCcsyHGxmX6a1oPVIUkvgQuAXSaeYWWl0Ma65pBwze0/SBcAAM/u3pL9GM643SFEg3RW4BjjbzJZEu74FPgceJPSvn2Bmrzami3Gp5DXTLBXTt/U7YBbQLZr1ZqKkN8zsFOBUYCcz+yBd5UyTHwgX4MoJF1kASoALCPNSQpg1vVn0Of5c7yWsY5I2lnRgzEsFwJNm9j9JLQDM7FNCzfyfhJbLK9HrHkjXgc8alaUktTOz5ZLaEWqg5YSLTZOAfwHXmdm76SxjfYu72NQE2Bq4CCgxs0sl3QtsQqiRdQeOb6h/aCQdCrwHLAW+J3RznG5mO8ek2RkoN7Np6Sllw+LBNAtJOpmw4Fcx8K6Z/TNm32DgemCfmOZcgxcXSLsQKljF0aqT5wOfm9llkgoJ6/t8ZGbF6Stx3Yuu2l8FvGlmj0l6HGgNnAgUAv8ATjazl9NYzAbDg2mWiWocIwmDzrckXGBaBlxGuHp/JXBYQ61xJSLpPH4d8jOH0E+4PnAusBo4tSE3Y+P+qDQlBM4ewH+BicDfgLaERfduNLPJ6SprQ+PBNMPFXwyQdDzQ2szuiPq+tiYEiisIfYXNzSwTVk6td1Gz9TZgX8Johr8Dq8zsDEnbACcB15vZ52ksZp2TtDshWM6PLkYOJ1xgesHM/h2lqegm8otNKeJX8zOYpPUINc8Xo2UWPgCWA3+W9IKZzQNmRf2mHcxsevpKW/+qCATfES40rWdm30ZjS9+WdIKZ3S/pooZ61V5Sk2gYWB/gEeAN4GdJ/zWzUZLKgcGSWhGGQH0DfrEplTyYZrYc4BBJIwl9XQOjfsDNgbskXUMYH7gRa6+u2KDFNWePA94h1MzLCLeJvmNmKyQ9A/wE0BADqaRmZlYWBdJ+hK6eg83sXUmDgD9KIgqoucAsD6B1w4NpBjOznySNBvYDXgEWRb8Q/yD0/11ICB4nmVlJ+kpa/2IC6RnAycARZlYk6WXgbOBjSWXA4YSLdQ2OpA6EVsoVZvYdocvnVOA5wq2yrxJu3BgmKdcnM6lb3meawaJflvUIgfNGQjP2OjP7XNL6ZvaDpPXMrMGNk6yOpA2BFRZWmNwUGA0cG9tPLGk/whX7LYEHzeyj9JS27kWtlF+Admb2jqQLgUuAHc3s46gLaE9ggZnNTmdZGzoPphkqqnH1B4qAecDDhHGkRYRB5ocQJjP5trE02yR1I9Q0bwVWEQbeTwD2M7OVkpqa2SpJHczsq3SWta5Fd3KVR88vB/YBzoma9xcB5wH9zGxuVCtdnc7yNgZ+B1QGkjSUMI3eyUB7YE8z+54wzOXb6LWjzGxlYwmkAGZWRLhCvzWwr4W5SGcDt0UBY5WkEYT1zps35Ak7zKxcUjdJO5rZVYQ14K+R1NPMbiYMgXpd0gaEmqurY14zzTDRfeX7AQuBXsAQ4KCoWdvFzBY0tppGRVCM6Se9EugM3E+YpOQsYHdCLXUgMKyhjrONmbRkF8KA/PWB08xstqTLgD7A1WY2Q9Lm0S2jrh54MM0gCjPkNyNcfb4RmGZm/aJ9JwHdgMvNrCx9paxfcVftDwG+MLM3osCRBzxNGJB+GOFq/nwz+zhtBa4HkvYh3OV2A2Hs7GLgPjObHo3w6EXoDvmuMbVc0s2DaYaQdAphPslDzKxE0o2EO1fOAAYApxCa9nPSWMy0kXQ+cCThYtO86LULga2AMcArjeVCnKS/Al+a2U0K0+ddDewAXBDVULdo6H9QMpH3mWaA6E6mA4G/AGWSTiNcZNqecDvkXjSyQBrb3xndvTSEcMHtY0n9JB1nZn8lzE8wgDDqoUGTdJDCEjSzgK6S8qNWyqWE8cbHSmoZXcVvsP3FmcrHmWYAM/tR0mRC020xYcXMhcAThNtEf25sfaQxTfv+hNEMpYRhUJ8DGwMbStrQzK6Nrt7/kL4S1z1J2wNnApcT/oDsAewj6VVCpehTYCfCRctbvXlf/zyYZo6HCXfxfGJmX0s6GjiU0BXTaAIpVLrQtC9hCr0jCBO4nAD8I7rf/HjCHJ00xGFQCjNfbW9mz0bjac8FfjGzGdH+l4CdgeMI9+EPAXYk/KFxaeB9phlGYR7O4wm/PEc21KvSiUjaCXgWONfMxsTtO4HQlzysoXZ9SOpFqHHOj+YZGEHoN7/PzO6P0rQHNiB0Ce0A3ES4E6xBfiaZzvtMM09zwrjAwxtTIK2ij28W4RbaK6KLLEhqIWkrwhpOxzXkoGFmM4GvgBmSRpjZA4TVA3aSNCxK87WZLSKM/jiN8Me3wX4mmc5rphmoitmQGrS4PtL9CbWtdwnB5DpgC8Iohx8U5ujMMbMf01bgeiBpI8KwpyWEmzXuiyYrOZqwkugLZvZQTPqmDXEil2zifaYZqDEFUqjUR3ohYdD9DMIkLn+O/r8R+K+kvRp6EI2xDPg94W63U4EHJf1sYcb8HEL/eqxGMSwsk3kz32UEheVFtjGzPQlzkq4EXiMEiT8TZkDqmL4S1g9JeZK6Rvfdn06YrKUNcA5wpaRjzexhM3s/9n2N7Q9wJvJmvks7hQmNdyXcIroR0A4YZGY/Szoc+I+ZfZ3GItaL6D76GwmjFMYBjxEmLFlkZo9Hdz6tMrNX01hMVw1v5ru0ii487UkY1jMN2BY4MwqkwwnLM7+WvhLWHzP7XtIlwHaEmbE2IXw2W0iaaWYvQePrU88WXjN1aRMzJ2suYULj5YSbFjYHviTUVg9vjFeoJeURbiceRFg8cQ8zm5XeUrmaeDB1aSFpb0Kta7qZTYwG6G8DPE9o6rcnLLHRKBcHjCVpS2vAE1w3FN7Md+lSTKiB3iRpC8JqAoOB183slXQWLFMoWiSvIpB68z6zec3UpZWkLYGhhKkH/wyMBY4BVnvgcNnEg6lLu+gOJxHGlD7pTVqXjTyYurTz5qtrCDyYOudcCvgdUM45lwIeTJ1zLgU8mDrnXAp4MHXOuRTwYOqccyngwdStE0nlkt6V9IGksZLWr0Vee0maGD0fJOniGtK2lXT6OhxjZDRfalKvx6UZJWnIbzhWZ0mNZpUEF3gwdevqRzPb3sy2AVYRJjBeQ8Fv/n6Z2Xgzu6GGJG0J83w6l1E8mLpUeBXoFtXI5kn6G2ENp06S9pP0pqRZUQ22JYCkAyTNl/Qa8MeKjCQNl3R39HxjSc9Kmh09dgFuIKwZ/66km6N0F0maLuk9SVfG5HWppA8l/QfYKtFJSDopyme2pKfjatv9JL0q6SNJA6L0OZJujjn2KbX9IF328mDqaiWaPu9AoGLm962Ah82sJ/A9cBnQz8x2ICxHcr6k5sA/CUuU7E6Yt7MqdwKvmNnvCatvzgEuJiyHvb2ZXSRpP8IaUX2B7YFekvaIVvccCvQkBOs+SZzOM2bWJzrePMLS0hU6E2a56g/cG53DCcAKM+sT5X+SwhLNrhHyWaPcumoh6d3o+avA/UAesNDM3ope34kwJ+fr0eKjTYE3ge7AAjP7GEDSo8DJVRxjb+BYgGgZjxWS2sWl2S96VKyJ1JIQXFsBz5rZD9ExxidxTttIuobQldASmBKz70kz+wX4WNKn0TnsB2wX05/aJjq2zy3QCHkwdevqRzPbPvaFKGB+H/sS8KKZHRmXbnsgVfcxC7jezP4Rd4xz1+EYo4CDzWx2NMv/XjH74vOy6NhnmVls0EVS5994XNcAeDPf1aW3gF0ldYMws3405d58oIukrlG6I6t5/0uE9eAr+idbA98Sap0VpgAjYvpi8xWWSf4fcIikFpJaEboUEmkFLJG0HnB03L7DJDWJyrw58GF07NOi9EjaMlrHyTVCXjN1dcbMlkY1vCeiafYALjOzjySdDEyS9BVhjadtqsjiHOA+SScA5cBpZvampNejoUfPRf2mWwNvRjXj74BjzGyWpDHAu8BCQldEIn8B3o7Sv0/loP0h8AqwMXCqmf0k6V+EvtRZCgdfChyc3KfjGhqfNco551LAm/nOOZcCHkydcy4FPJg651wKeDB1zrkU8GDqnHMp4MHUOedSwIOpc86lwP8Dsd0b3iI5A04AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confMat, classes=iris.target_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confMat, classes=iris.target_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Different data sets\n",
    "\n",
    "Up until now, we've mostly just used a single data set for each assignment; that was fine when we were focused mainly on understanding how the classifiers worked, but we also need to get a feel for how much difference there is between different data sets.  Here, we will load up several different data sets provided by SciKit learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "digits = datasets.load_digits()\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use what you've learned\n",
    "\n",
    "Use what you've learned from the earlier parts of this assignment to compare the performance of each of the classifiers we've studied (KNN, SVM, Decision Tree, Random Forest) on each of these datasets.  For each dataset, make sure you include markdown cells explaning which classifier you would recommend for that data set and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9593333333333334 , stdDev = 0.0515493291259288\n",
      "Linear SVM: mean = 0.9786666666666668 , stdDev = 0.03512517299285197\n",
      "Decision Tree: mean =  0.9460000000000001 , stdDev = 0.06373207809084666\n",
      "Random Forst: mean =  0.9513333333333336 , stdDev = 0.055661676423031145\n",
      "Difference between means: 0.019333333333333425\n",
      "Difference between means (decison tree):  -0.03266666666666673 -0.013333333333333308\n",
      "Difference between means (random forest):  0.005333333333333523 -0.02733333333333321 -0.007999999999999785\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "decTree = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "nnScores = cross_val_score(nn, iris.data, iris.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, iris.data, iris.target, cv = rkf)\n",
    "decTreeScores = cross_val_score(decTree, iris.data, iris.target, cv = rkf)\n",
    "clfScores = cross_val_score(clf, iris.data, iris.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Decision Tree: mean = ', decTreeScores.mean(), ', stdDev =', decTreeScores.std())\n",
    "print('Random Forst: mean = ',clfScores.mean(), ', stdDev =', clfScores.std())\n",
    "print('Difference between means (svm, nn):', svmScores.mean() - nnScores.mean())\n",
    "print('Difference between means (decison tree): ', decTreeScores.mean() - svmScores.mean(), decTreeScores.mean() - nnScores.mean())\n",
    "print('Difference between means (random forest): ', clfScores.mean() - decTreeScores.mean(), clfScores.mean() - svmScores.mean(), clfScores.mean() - nnScores.mean())\n",
    "# scipy.stats.mannwhitneyu(nnScores, svmScores, decTreeScores, clfScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data above we see that in terms of the mean. The different classifiers rank as:\n",
    "* SVM\n",
    "* NN\n",
    "* Random Forest\n",
    "* Decision Tree\n",
    "\n",
    "For standard deviation, they rank the same. At first glance after running the k-fold cross validation, SVM is the best classifier for the iris data set.\n",
    "\n",
    "Confusion matrix below will help decide if that is the final suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: \n",
      " [[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  1 20]]\n",
      "nn: \n",
      " [[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  4 17]]\n",
      "decTree: \n",
      " [[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  2 19]]\n",
      "forest: \n",
      " [[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  3 18]]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "svmLinear.fit(train, trainLabels)\n",
    "predictions = svmLinear.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"svm: \\n\",confMat)\n",
    "\n",
    "nn.fit(train, trainLabels)\n",
    "predictions = nn.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"nn: \\n\",confMat)\n",
    "\n",
    "decTree.fit(train, trainLabels)\n",
    "predictions = decTree.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"decTree: \\n\",confMat)\n",
    "\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"forest: \\n\",confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrices. We see that the first column and top row of every matrix is the same. The differences come in the second and third rows and columns. We see that the SVM classifier misclassified the data the least compared to the rest of the different classifiers.\n",
    "\n",
    "After comparing the means, standard deviations, and confusion matrices. It is decided that the SVM classifier is the best classifier for the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9145833333333333 , stdDev = 0.03585050679546383\n",
      "Linear SVM: mean = 0.9555388471177946 , stdDev = 0.023112007872180734\n",
      "Decision Tree: mean =  0.9231547619047619 , stdDev = 0.033276584741569616\n",
      "Random Forst: mean =  0.9599373433583959 , stdDev = 0.0235827679951517\n",
      "Difference between means: 0.04095551378446127\n",
      "Difference between means (decison tree):  -0.03238408521303271 0.008571428571428563\n",
      "Difference between means (random forest):  0.036782581453634 0.004398496240601291 0.04535401002506256\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "decTree = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "nnScores = cross_val_score(nn, cancer.data, cancer.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, cancer.data, cancer.target, cv = rkf)\n",
    "decTreeScores = cross_val_score(decTree, cancer.data, cancer.target, cv = rkf)\n",
    "clfScores = cross_val_score(clf, cancer.data, cancer.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Decision Tree: mean = ', decTreeScores.mean(), ', stdDev =', decTreeScores.std())\n",
    "print('Random Forst: mean = ',clfScores.mean(), ', stdDev =', clfScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "print('Difference between means (decison tree): ', decTreeScores.mean() - svmScores.mean(), decTreeScores.mean() - nnScores.mean())\n",
    "print('Difference between means (random forest): ', clfScores.mean() - decTreeScores.mean(), clfScores.mean() - svmScores.mean(), clfScores.mean() - nnScores.mean())\n",
    "# scipy.stats.mannwhitneyu(nnScores, svmScores, decTreeScores, clfScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data above we see that in terms of the mean. The different classifiers rank as:\n",
    "* Forest\n",
    "* SVM\n",
    "* Decision Tree\n",
    "* NN\n",
    "\n",
    "For standard deviation, it should be noted that forest has a slightly lower standard deviation then the SVM. The difference is very marginal between the two.\n",
    "\n",
    "Confusion matrix below will help decide whether the SVM classifier or the forest classifier is better for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: \n",
      " [[ 80   3]\n",
      " [  3 142]]\n",
      "nn: \n",
      " [[ 74   9]\n",
      " [  7 138]]\n",
      "decTree: \n",
      " [[ 69  14]\n",
      " [ 15 130]]\n",
      "forest: \n",
      " [[ 74   9]\n",
      " [  3 142]]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(cancer.data, cancer.target, test_size=0.4, random_state=0)\n",
    "\n",
    "svmLinear.fit(train, trainLabels)\n",
    "predictions = svmLinear.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"svm: \\n\",confMat)\n",
    "\n",
    "nn.fit(train, trainLabels)\n",
    "predictions = nn.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"nn: \\n\",confMat)\n",
    "\n",
    "decTree.fit(train, trainLabels)\n",
    "predictions = decTree.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"decTree: \\n\",confMat)\n",
    "\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"forest: \\n\",confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above the SVM and Forest were very close in comparison. By analyzing the confusion matrix above, it can be seen that Forest has several more elements misclassified than the SVM does.\n",
    "\n",
    "Thus, the edge for better classifier of the cancer dataset is given to the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.9881474239602731 , stdDev = 0.007737237689586699\n",
      "Linear SVM: mean = 0.9799106145251396 , stdDev = 0.010283028673791843\n",
      "Decision Tree: mean =  0.853634698944755 , stdDev = 0.02598402996447224\n",
      "Random Forst: mean =  0.9776834264432032 , stdDev = 0.009811053056271616\n",
      "Difference between means: -0.008236809435133496\n",
      "Difference between means (decison tree):  -0.12627591558038465 -0.13451272501551814\n",
      "Difference between means (random forest):  0.1240487274984482 -0.0022271880819364487 -0.010463997517069945\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "decTree = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "nnScores = cross_val_score(nn, digits.data, digits.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, digits.data, digits.target, cv = rkf)\n",
    "decTreeScores = cross_val_score(decTree, digits.data, digits.target, cv = rkf)\n",
    "clfScores = cross_val_score(clf, digits.data, digits.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Decision Tree: mean = ', decTreeScores.mean(), ', stdDev =', decTreeScores.std())\n",
    "print('Random Forst: mean = ',clfScores.mean(), ', stdDev =', clfScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "print('Difference between means (decison tree): ', decTreeScores.mean() - svmScores.mean(), decTreeScores.mean() - nnScores.mean())\n",
    "print('Difference between means (random forest): ', clfScores.mean() - decTreeScores.mean(), clfScores.mean() - svmScores.mean(), clfScores.mean() - nnScores.mean())\n",
    "# scipy.stats.mannwhitneyu(nnScores, svmScores, decTreeScores, clfScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data above we see that in terms of the mean. The different classifiers rank as:\n",
    "* NN\n",
    "* SVM\n",
    "* Random Forest\n",
    "* Decision Tree\n",
    "\n",
    "For standard deviation:\n",
    "* NN\n",
    "* Random Forest\n",
    "* SVM\n",
    "* Decision Tree\n",
    "\n",
    "The story for this classifier comparison is a little interesting. Nearset Neighbors has the best mean and the best standard deviation compared to everything else. However, SVM has a very close mean to NN and Forest has a very close standard deviation to NN. The differences between them all are very small as well. \n",
    "\n",
    "Confusion matrix below will give us a better picture overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: \n",
      " [[60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 71  0  0  0  1  0  0  1  0]\n",
      " [ 0  1 70  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 69  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 63  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 86  1  0  0  1]\n",
      " [ 0  1  0  0  0  0 75  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 64  1  0]\n",
      " [ 0  2  0  1  1  1  0  0 72  1]\n",
      " [ 0  0  0  2  0  1  0  0  0 71]]\n",
      "nn: \n",
      " [[60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 73  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 71  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 70  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 63  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 87  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 76  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 65  0  0]\n",
      " [ 0  2  0  1  0  0  0  0 74  1]\n",
      " [ 0  0  0  2  0  1  0  0  0 71]]\n",
      "decTree: \n",
      " [[59  0  0  0  0  1  0  0  0  0]\n",
      " [ 5 56  0  1  0  1  2  3  3  2]\n",
      " [ 5  1 49  3  1  0  0  1  8  3]\n",
      " [ 0  0  1 60  0  3  1  1  1  3]\n",
      " [ 0  1  0  1 53  0  1  6  0  1]\n",
      " [ 0  4  0  2  3 65  1  3  7  4]\n",
      " [ 0  1  0  0  0  1 73  1  0  0]\n",
      " [ 0  0  0  0  2  3  0 59  0  1]\n",
      " [ 0  6  4  5  0  1  0  4 46 12]\n",
      " [ 1  2  0  2  0  5  2  2  0 60]]\n",
      "forest: \n",
      " [[60  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  0  1  0  0  0  0]\n",
      " [ 1  1 68  1  0  0  0  0  0  0]\n",
      " [ 0  1  0 67  0  0  0  1  1  0]\n",
      " [ 0  0  0  0 62  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 86  1  0  0  1]\n",
      " [ 0  1  0  0  0  1 74  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 65  0  0]\n",
      " [ 0  3  0  0  0  0  0  1 74  0]\n",
      " [ 0  0  0  1  0  1  0  1  0 71]]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(digits.data, digits.target, test_size=0.4, random_state=0)\n",
    "\n",
    "svmLinear.fit(train, trainLabels)\n",
    "predictions = svmLinear.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"svm: \\n\",confMat)\n",
    "\n",
    "nn.fit(train, trainLabels)\n",
    "predictions = nn.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"nn: \\n\",confMat)\n",
    "\n",
    "decTree.fit(train, trainLabels)\n",
    "predictions = decTree.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"decTree: \\n\",confMat)\n",
    "\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"forest: \\n\",confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that the nearest neighbor has definitely misclassified the lowest amount of data. The interesting part is that Nearest Neighbor, SVM, and Forest all have a very similar pattern in their confusion matrices. However, where the SVM and Random Forest have some misclassifications the Nearest Neighbor classifier does not. \n",
    "\n",
    "Thus, the Nearest Neighbor classifier is the best classifier for the digits dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbor: mean = 0.763235294117647 , stdDev = 0.09930917667611418\n",
      "Linear SVM: mean = 0.9507843137254902 , stdDev = 0.04562966936624376\n",
      "Decision Tree: mean =  0.9050653594771242 , stdDev = 0.07082744357387699\n",
      "Random Forst: mean =  0.9814705882352942 , stdDev = 0.030854432860920298\n",
      "Difference between means: 0.1875490196078432\n",
      "Difference between means (decison tree):  -0.04571895424836603 0.14183006535947718\n",
      "Difference between means (random forest):  0.07640522875817002 0.03068627450980399 0.2182352941176472\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits = 10, n_repeats = 10)\n",
    "\n",
    "nn = neighbors.KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "svmLinear = svm.SVC(kernel='linear')\n",
    "decTree = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "nnScores = cross_val_score(nn, wine.data, wine.target, cv = rkf)\n",
    "svmScores = cross_val_score(svmLinear, wine.data, wine.target, cv = rkf)\n",
    "decTreeScores = cross_val_score(decTree, wine.data, wine.target, cv = rkf)\n",
    "clfScores = cross_val_score(clf, wine.data, wine.target, cv = rkf)\n",
    "\n",
    "print('Nearest Neighbor: mean =', nnScores.mean(), ', stdDev =', nnScores.std())\n",
    "print('Linear SVM: mean =', svmScores.mean(), ', stdDev =', svmScores.std())\n",
    "print('Decision Tree: mean = ', decTreeScores.mean(), ', stdDev =', decTreeScores.std())\n",
    "print('Random Forst: mean = ',clfScores.mean(), ', stdDev =', clfScores.std())\n",
    "print('Difference between means:', svmScores.mean() - nnScores.mean())\n",
    "print('Difference between means (decison tree): ', decTreeScores.mean() - svmScores.mean(), decTreeScores.mean() - nnScores.mean())\n",
    "print('Difference between means (random forest): ', clfScores.mean() - decTreeScores.mean(), clfScores.mean() - svmScores.mean(), clfScores.mean() - nnScores.mean())\n",
    "# scipy.stats.mannwhitneyu(nnScores, svmScores, decTreeScores, clfScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the data above we see that in terms of the mean. The different classifiers rank as:\n",
    "* Random Forest\n",
    "* SVM\n",
    "* Decision Tree\n",
    "* NN\n",
    "\n",
    "For standard deviation, they rank the same. At first glance after running the k-fold cross validation, Random Forest is the best classifier for the wine data set.\n",
    "\n",
    "Confusion matrix below will help decide if that is the final suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: \n",
      " [[22  0  0]\n",
      " [ 0 28  3]\n",
      " [ 0  0 19]]\n",
      "nn: \n",
      " [[19  1  2]\n",
      " [ 1 25  5]\n",
      " [ 3  6 10]]\n",
      "decTree: \n",
      " [[22  0  0]\n",
      " [ 0 28  3]\n",
      " [ 1  1 17]]\n",
      "forest: \n",
      " [[22  0  0]\n",
      " [ 0 29  2]\n",
      " [ 0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "train, test, trainLabels, testLabels = train_test_split(wine.data, wine.target, test_size=0.4, random_state=0)\n",
    "\n",
    "svmLinear.fit(train, trainLabels)\n",
    "predictions = svmLinear.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"svm: \\n\",confMat)\n",
    "\n",
    "nn.fit(train, trainLabels)\n",
    "predictions = nn.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"nn: \\n\",confMat)\n",
    "\n",
    "decTree.fit(train, trainLabels)\n",
    "predictions = decTree.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"decTree: \\n\",confMat)\n",
    "\n",
    "clf.fit(train, trainLabels)\n",
    "predictions = clf.predict(test)\n",
    "confMat = confusion_matrix(testLabels, predictions)\n",
    "print(\"forest: \\n\",confMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest have 1 less misclassified value then the SVM classifier does in the confusion matrices. However, since the Random Forest had a better mean and standard deviation as well in the previous section, then it is best to give the edge to Random Forest for the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
